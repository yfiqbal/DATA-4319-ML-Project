{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "862cadb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c19a4a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42467b65",
   "metadata": {},
   "source": [
    "Fashion dataset for predicting fashion categories\n",
    "The classes are:\n",
    "\n",
    "Label\tDescription  \n",
    "0\tT-shirt/top  \n",
    "1\tTrouser  \n",
    "2\tPullover  \n",
    "3\tDress  \n",
    "4\tCoat  \n",
    "5\tSandal  \n",
    "6\tShirt  \n",
    "7\tSneaker  \n",
    "8\tBag  \n",
    "9\tAnkle boot  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8436a98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "495c3a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a5d018c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "161f108a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
       "          1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
       "          0,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
       "         10,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
       "         72,  15],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
       "        172,  66],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
       "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
       "        229,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
       "        173,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
       "        202,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
       "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
       "        209,  52],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
       "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
       "        167,  56],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
       "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
       "         92,   0],\n",
       "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
       "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
       "         77,   0],\n",
       "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
       "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
       "        159,   0],\n",
       "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
       "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
       "        215,   0],\n",
       "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
       "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
       "        246,   0],\n",
       "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
       "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
       "        225,   0],\n",
       "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
       "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
       "        229,  29],\n",
       "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
       "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
       "        230,  67],\n",
       "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
       "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
       "        206, 115],\n",
       "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
       "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
       "        210,  92],\n",
       "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
       "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
       "        170,   0],\n",
       "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
       "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e0363e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18cb2a55a90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_train[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be4f01fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9de1c7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, 3, 0], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df81005c",
   "metadata": {},
   "source": [
    "### Flatten dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bef2e8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03bda014",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54242d3",
   "metadata": {},
   "source": [
    "Dividing by 255 scales the arrays for more accuracy in the model. We use 255 as that is the maximum RGB value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f1761e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
       "        0.05098039, 0.28627451, 0.        , 0.        , 0.00392157,\n",
       "        0.01568627, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00392157, 0.00392157, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.        , 0.14117647,\n",
       "        0.53333333, 0.49803922, 0.24313725, 0.21176471, 0.        ,\n",
       "        0.        , 0.        , 0.00392157, 0.01176471, 0.01568627,\n",
       "        0.        , 0.        , 0.01176471],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.02352941, 0.        , 0.4       ,\n",
       "        0.8       , 0.69019608, 0.5254902 , 0.56470588, 0.48235294,\n",
       "        0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04705882, 0.03921569, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.60784314,\n",
       "        0.9254902 , 0.81176471, 0.69803922, 0.41960784, 0.61176471,\n",
       "        0.63137255, 0.42745098, 0.25098039, 0.09019608, 0.30196078,\n",
       "        0.50980392, 0.28235294, 0.05882353],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00392157, 0.        , 0.27058824, 0.81176471,\n",
       "        0.8745098 , 0.85490196, 0.84705882, 0.84705882, 0.63921569,\n",
       "        0.49803922, 0.4745098 , 0.47843137, 0.57254902, 0.55294118,\n",
       "        0.34509804, 0.6745098 , 0.25882353],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.00392157, 0.00392157, 0.        , 0.78431373, 0.90980392,\n",
       "        0.90980392, 0.91372549, 0.89803922, 0.8745098 , 0.8745098 ,\n",
       "        0.84313725, 0.83529412, 0.64313725, 0.49803922, 0.48235294,\n",
       "        0.76862745, 0.89803922, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.71764706, 0.88235294,\n",
       "        0.84705882, 0.8745098 , 0.89411765, 0.92156863, 0.89019608,\n",
       "        0.87843137, 0.87058824, 0.87843137, 0.86666667, 0.8745098 ,\n",
       "        0.96078431, 0.67843137, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.75686275, 0.89411765,\n",
       "        0.85490196, 0.83529412, 0.77647059, 0.70588235, 0.83137255,\n",
       "        0.82352941, 0.82745098, 0.83529412, 0.8745098 , 0.8627451 ,\n",
       "        0.95294118, 0.79215686, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.01176471, 0.        , 0.04705882, 0.85882353, 0.8627451 ,\n",
       "        0.83137255, 0.85490196, 0.75294118, 0.6627451 , 0.89019608,\n",
       "        0.81568627, 0.85490196, 0.87843137, 0.83137255, 0.88627451,\n",
       "        0.77254902, 0.81960784, 0.20392157],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02352941, 0.        , 0.38823529, 0.95686275, 0.87058824,\n",
       "        0.8627451 , 0.85490196, 0.79607843, 0.77647059, 0.86666667,\n",
       "        0.84313725, 0.83529412, 0.87058824, 0.8627451 , 0.96078431,\n",
       "        0.46666667, 0.65490196, 0.21960784],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01568627,\n",
       "        0.        , 0.        , 0.21568627, 0.9254902 , 0.89411765,\n",
       "        0.90196078, 0.89411765, 0.94117647, 0.90980392, 0.83529412,\n",
       "        0.85490196, 0.8745098 , 0.91764706, 0.85098039, 0.85098039,\n",
       "        0.81960784, 0.36078431, 0.        ],\n",
       "       [0.        , 0.        , 0.00392157, 0.01568627, 0.02352941,\n",
       "        0.02745098, 0.00784314, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.92941176, 0.88627451, 0.85098039,\n",
       "        0.8745098 , 0.87058824, 0.85882353, 0.87058824, 0.86666667,\n",
       "        0.84705882, 0.8745098 , 0.89803922, 0.84313725, 0.85490196,\n",
       "        1.        , 0.30196078, 0.        ],\n",
       "       [0.        , 0.01176471, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.24313725,\n",
       "        0.56862745, 0.8       , 0.89411765, 0.81176471, 0.83529412,\n",
       "        0.86666667, 0.85490196, 0.81568627, 0.82745098, 0.85490196,\n",
       "        0.87843137, 0.8745098 , 0.85882353, 0.84313725, 0.87843137,\n",
       "        0.95686275, 0.62352941, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.07058824,\n",
       "        0.17254902, 0.32156863, 0.41960784, 0.74117647, 0.89411765,\n",
       "        0.8627451 , 0.87058824, 0.85098039, 0.88627451, 0.78431373,\n",
       "        0.80392157, 0.82745098, 0.90196078, 0.87843137, 0.91764706,\n",
       "        0.69019608, 0.7372549 , 0.98039216, 0.97254902, 0.91372549,\n",
       "        0.93333333, 0.84313725, 0.        ],\n",
       "       [0.        , 0.22352941, 0.73333333, 0.81568627, 0.87843137,\n",
       "        0.86666667, 0.87843137, 0.81568627, 0.8       , 0.83921569,\n",
       "        0.81568627, 0.81960784, 0.78431373, 0.62352941, 0.96078431,\n",
       "        0.75686275, 0.80784314, 0.8745098 , 1.        , 1.        ,\n",
       "        0.86666667, 0.91764706, 0.86666667, 0.82745098, 0.8627451 ,\n",
       "        0.90980392, 0.96470588, 0.        ],\n",
       "       [0.01176471, 0.79215686, 0.89411765, 0.87843137, 0.86666667,\n",
       "        0.82745098, 0.82745098, 0.83921569, 0.80392157, 0.80392157,\n",
       "        0.80392157, 0.8627451 , 0.94117647, 0.31372549, 0.58823529,\n",
       "        1.        , 0.89803922, 0.86666667, 0.7372549 , 0.60392157,\n",
       "        0.74901961, 0.82352941, 0.8       , 0.81960784, 0.87058824,\n",
       "        0.89411765, 0.88235294, 0.        ],\n",
       "       [0.38431373, 0.91372549, 0.77647059, 0.82352941, 0.87058824,\n",
       "        0.89803922, 0.89803922, 0.91764706, 0.97647059, 0.8627451 ,\n",
       "        0.76078431, 0.84313725, 0.85098039, 0.94509804, 0.25490196,\n",
       "        0.28627451, 0.41568627, 0.45882353, 0.65882353, 0.85882353,\n",
       "        0.86666667, 0.84313725, 0.85098039, 0.8745098 , 0.8745098 ,\n",
       "        0.87843137, 0.89803922, 0.11372549],\n",
       "       [0.29411765, 0.8       , 0.83137255, 0.8       , 0.75686275,\n",
       "        0.80392157, 0.82745098, 0.88235294, 0.84705882, 0.7254902 ,\n",
       "        0.77254902, 0.80784314, 0.77647059, 0.83529412, 0.94117647,\n",
       "        0.76470588, 0.89019608, 0.96078431, 0.9372549 , 0.8745098 ,\n",
       "        0.85490196, 0.83137255, 0.81960784, 0.87058824, 0.8627451 ,\n",
       "        0.86666667, 0.90196078, 0.2627451 ],\n",
       "       [0.18823529, 0.79607843, 0.71764706, 0.76078431, 0.83529412,\n",
       "        0.77254902, 0.7254902 , 0.74509804, 0.76078431, 0.75294118,\n",
       "        0.79215686, 0.83921569, 0.85882353, 0.86666667, 0.8627451 ,\n",
       "        0.9254902 , 0.88235294, 0.84705882, 0.78039216, 0.80784314,\n",
       "        0.72941176, 0.70980392, 0.69411765, 0.6745098 , 0.70980392,\n",
       "        0.80392157, 0.80784314, 0.45098039],\n",
       "       [0.        , 0.47843137, 0.85882353, 0.75686275, 0.70196078,\n",
       "        0.67058824, 0.71764706, 0.76862745, 0.8       , 0.82352941,\n",
       "        0.83529412, 0.81176471, 0.82745098, 0.82352941, 0.78431373,\n",
       "        0.76862745, 0.76078431, 0.74901961, 0.76470588, 0.74901961,\n",
       "        0.77647059, 0.75294118, 0.69019608, 0.61176471, 0.65490196,\n",
       "        0.69411765, 0.82352941, 0.36078431],\n",
       "       [0.        , 0.        , 0.29019608, 0.74117647, 0.83137255,\n",
       "        0.74901961, 0.68627451, 0.6745098 , 0.68627451, 0.70980392,\n",
       "        0.7254902 , 0.7372549 , 0.74117647, 0.7372549 , 0.75686275,\n",
       "        0.77647059, 0.8       , 0.81960784, 0.82352941, 0.82352941,\n",
       "        0.82745098, 0.7372549 , 0.7372549 , 0.76078431, 0.75294118,\n",
       "        0.84705882, 0.66666667, 0.        ],\n",
       "       [0.00784314, 0.        , 0.        , 0.        , 0.25882353,\n",
       "        0.78431373, 0.87058824, 0.92941176, 0.9372549 , 0.94901961,\n",
       "        0.96470588, 0.95294118, 0.95686275, 0.86666667, 0.8627451 ,\n",
       "        0.75686275, 0.74901961, 0.70196078, 0.71372549, 0.71372549,\n",
       "        0.70980392, 0.69019608, 0.65098039, 0.65882353, 0.38823529,\n",
       "        0.22745098, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15686275, 0.23921569, 0.17254902,\n",
       "        0.28235294, 0.16078431, 0.1372549 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10dde673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flattened = X_train.reshape(len(X_train),28*28)\n",
    "X_train_flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a97d78ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b72f8152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_flattened = X_test.reshape(len(X_test),28*28)\n",
    "X_test_flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1cce991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 990us/step - loss: 0.5980 - accuracy: 0.7979\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 492us/step - loss: 0.4609 - accuracy: 0.8425\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 493us/step - loss: 0.4364 - accuracy: 0.8503\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 473us/step - loss: 0.4231 - accuracy: 0.8541\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 442us/step - loss: 0.4133 - accuracy: 0.8574\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 468us/step - loss: 0.4070 - accuracy: 0.8595\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 495us/step - loss: 0.4024 - accuracy: 0.8610\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 470us/step - loss: 0.3985 - accuracy: 0.8610\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 1s 472us/step - loss: 0.3940 - accuracy: 0.8626\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 1s 453us/step - loss: 0.3923 - accuracy: 0.8638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18cb261ceb0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(10, input_shape=(784,), activation='sigmoid')\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.fit(X_train_flattened, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60674098",
   "metadata": {},
   "source": [
    "Approximately 86.4% accuracy after 10 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "889bb722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 381us/step - loss: 0.4556 - accuracy: 0.8425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.45559999346733093, 0.8424999713897705]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_flattened, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1adc4e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.4291873e-04, 1.8825474e-05, 1.2088418e-02, 2.9436946e-03,\n",
       "       5.0359666e-03, 9.8596084e-01, 2.2016227e-02, 9.8130667e-01,\n",
       "       7.8574604e-01, 9.9846923e-01], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = model.predict(X_test_flattened)\n",
    "y_predicted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9dc163a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_predicted[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1229462d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 2, 1, 1, 6]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_labels = [np.argmax(i) for i in y_predicted]\n",
    "y_predicted_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6ed62db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
       "array([[799,   2,  32,  53,   6,   0,  96,   0,  12,   0],\n",
       "       [  3, 955,   6,  27,   5,   0,   2,   0,   2,   0],\n",
       "       [ 15,   6, 835,  11,  92,   1,  38,   0,   2,   0],\n",
       "       [ 19,  11,  30, 868,  40,   0,  26,   1,   5,   0],\n",
       "       [  0,   0, 191,  27, 734,   0,  44,   0,   4,   0],\n",
       "       [  0,   0,   0,   1,   0, 909,   0,  64,   2,  24],\n",
       "       [123,   2, 207,  43, 123,   0, 485,   0,  17,   0],\n",
       "       [  0,   0,   0,   0,   0,  22,   0, 955,   0,  23],\n",
       "       [  4,   1,  14,   9,   3,   4,  16,   5, 944,   0],\n",
       "       [  0,   0,   0,   0,   0,  11,   1,  47,   0, 941]])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = tf.math.confusion_matrix(labels=y_test, predictions=y_predicted_labels)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab63da8",
   "metadata": {},
   "source": [
    "As shown by the confusion matrix, accuracy for most fashion categories are acceptable, however it appears quite low for the 7th label, shirt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f24ba6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 1s 538us/step - loss: 0.4852 - accuracy: 0.8286\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 548us/step - loss: 0.3674 - accuracy: 0.8666\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 536us/step - loss: 0.3306 - accuracy: 0.8796\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 544us/step - loss: 0.3078 - accuracy: 0.8868\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 545us/step - loss: 0.2881 - accuracy: 0.8930\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 540us/step - loss: 0.2738 - accuracy: 0.8978\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 535us/step - loss: 0.2619 - accuracy: 0.9018\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 536us/step - loss: 0.2494 - accuracy: 0.9064\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 1s 540us/step - loss: 0.2408 - accuracy: 0.9098\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 1s 536us/step - loss: 0.2295 - accuracy: 0.9142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18ccede0970>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(200, input_shape=(784,), activation='relu'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.fit(X_train_flattened, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7a6998",
   "metadata": {},
   "source": [
    "Adding a hidden layer has increased the accuracy of the model to approximately 91.4% after 10 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ab45862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 420us/step - loss: 0.3722 - accuracy: 0.8728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3721693754196167, 0.8727999925613403]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_flattened, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9dab0a",
   "metadata": {},
   "source": [
    "Before adding a hidden layer, accuracy was 86.4%, after adding a hidden layer it increased to 87.3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34800b56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
